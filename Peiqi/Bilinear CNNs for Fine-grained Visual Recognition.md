#### 什么是细粒度？
细粒度模型，通俗的讲就是将业务模型中的对象加以细分，从而得到更科学合理的对象模型，直观的说就是划分出很多对象。
细粒度图像分类是在区分出基本类别的基础上，进行更精细的子类划分，如区分鸟的种类、车的款式、狗的品种等，目前在工业界和实际生活中有着广泛的业务需求和应用场景。

细粒度图像相较于粗粒度图像具有更加相似的外观和特征，加之采集中存在姿态、视角、光照、遮挡、背景干扰等影响，导致数据呈现类间差异性大、类内差异性小的现象，从而使分类更加具有难度。

细粒度视觉分类（FGCV，Fine-Grained Visual Categorization）

即识别细分类别的任务，一般它需要同时使用全局图像信息与局部图像信息精准识别图像子类别。

解决方案：

一般细粒度识别可以分为两种，即**基于强监督信息的方法**和**仅使用弱监督信息**的方法。

基于强监督的细粒度识别通常需要使用**边界框**和**局部标注信息**，例如2014年提出的Part-based R-CNN利用自底向上的候选区域（region proposals）计算深度卷积特征而实现细粒度识别。这种方法会学习建模局部外观，并加强局部信息之间的几何约束。

仅使用弱监督信息的方法指数据集**只有类别标签**，是一种弱监督信息的细粒度识别。

#### 细粒度的本质问题是什么？
细粒度识别的类内差距大、类间差距小。

类内差距大：可能因为姿势、拍摄位置、光照等噪音带来的差异远大于能够区分物体的特征比如毛色、肢体等细微差异。

【那么，我们的任务就可以集中在如何排除噪音、或者如何选择特征？】
#### 什么是端到端训练？
**端到端指的是输入是原始数据，输出是最后的结果**。非端到端的输入端不是直接的原始数据，而是在原始数据中提取的特征，这一点在图像问题上尤为突出，因为图像像素太多，数据维度高，会产生维度灾难，所以原来一个思路是手工提取图像的一些关键特征，这实际就是一个降维的过程。那么问题来了，特征怎么提？特征提取的好坏异常关键，甚至比学习算法还重要，举个例子，对一系列人的数据分类，分类结果是性别，如果你提取的特征是头发的颜色，无论分类算法如何，分类效果都不会好，如果你提取的特征是头发的长短，这个特征就会好很多，但是还是会有错误，如果你提取了一个超强特征，比如染色体的数据，那你的分类基本就不会错了。这就意味着，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。于是就出现了端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中，不需要人来干预了。

相对于深度学习，传统机器学习的流程往往由多个独立的模块组成，比如在一个典型的自然语言处理（Natural Language Processing）问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，其结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端的。

而深度学习模型在训练过程中，从输入端（输入数据）到输出端会得到一个预测结果，与真实结果相比较会得到一个误差，这个误差会在模型中的每一层传递（反向传播），每一层的表示都会根据这个误差来做调整，直到模型收敛或达到预期的效果才结束，这是端到端的。

两者相比，端到端的学习省去了在每一个独立学习任务执行之前所做的数据标注，为样本做标注的代价是昂贵的、易出错的。
#### 什么是平移不变性？
不变性意味着即使目标的外观发生了某种变化，但是你依然可以把它识别出来。

这对图像分类来说是一种很好的特性，因为我们希望图像中目标无论是被平移，被旋转，还是被缩放，甚至是不同的光照条件、视角，都可以被成功地识别出来。

在欧几里得几何中，平移是一种几何变换，表示把一幅图像或一个空间中的每一个点在相同方向移动相同距离。比如对图像分类任务来说，图像中的目标不管被移动到图片的哪个位置，得到的结果（标签）应该是相同的，这就是卷积神经网络中的平移不变性。

平移不变性意味着系统产生完全相同的响应（输出），不管它的输入是如何平移的 。

#### 为什么卷积神经网络具有平移不变性？
简单地说，卷积+最大池化约等于平移不变性。

* 卷积：简单地说，图像经过平移，相应的特征图上的表达也是平移的。

输入图像的左下角有一个人脸，经过卷积，人脸的特征（眼睛，鼻子）也位于特征图的左下角。

在神经网络中，卷积被定义为不同位置的特征检测器，也就意味着，无论目标出现在图像中的哪个位置，它都会检测到同样的这些特征，输出同样的响应。比如人脸被移动到了图像左下角，卷积核直到移动到左下角的位置才会检测到它的特征。

* 池化：比如最大池化，它返回感受野中的最大值，如果最大值被移动了，但是仍然在这个感受野中，那么池化层也仍然会输出相同的最大值。这就有点平移不变的意思了。

所以这两种操作共同提供了一些平移不变性，即使图像被平移，卷积保证仍然能检测到它的特征，池化则尽可能地保持一致的表达。
#### 内框架代码？怎么处理输入？输出怎么进行loss计算？
#### 数据集的标注文件是怎么样的？


## Bilinear CNN Models for Fine-grained Visual Recognition（细粒度视觉识别之双线性CNN模型）
* what 
    
    双线性定义：包含两个特征提取器，其输出经过外积相乘、池化后获得图像描述子
    
    一种对Bilinear CNN模型的解释是，网络A的作用是对物体／部件进行定位，即完成前面介绍算法的物体与局部区域检测工作，而网络B则是用来对网络A检测到的物体位置进行特征提取。

    两个网络相互协调作用，完成了细粒度图像分类过程中两个最重要的任务：物体、局部区域的检测与特征提取。
    
* why
    
    人的视觉是有两个数据流，ventral stream 告诉人们这个object是什么， dorsal stream 告诉人们这个物体在哪儿。由于，我们的模型在两个CNN的输出是线性的，所以我们命名为biliner CNN

* how

细粒度识别即对隶属于同一类的目标进行分类，包括鸟的物种识别、汽车的型号识别和狗的品种识别。细粒度识别高度依赖目标的局部特征，例如，要将“加利福尼亚鸥”与“环嘴鸥”区分开来，需要识别其喙上的图案或它们羽毛的细微颜色差异。两类技术适合于解决细粒度分类任务。一是基于部件的识别模型，这些模型检测并提取部件的特征进行细粒度的类别区分。另一种方法是基于全局图像的整体模型。基于部件的模型往往更加精确，但由于图像部件标注成本太高，很难获取大规模的数据集，所以这种方法不实用。实际应用种往往更需要仅仅依据图像的类别信息完成细粒度识别任务。

这篇文章的主要思想是对于两个不同图像特征的处理方式上的不同。传统的，对于图像的不同特征，我们常用的方法是进行串联（连接），或者进行sum,或者max-pooling。论文的主要思想是，研究发现人类的大脑发现，人类的视觉处理主要有两个pathway, the ventral stream是进行物体识别的，the dorsal stream 是为了发现物体的位置。论文基于这样的思想，希望能够将两个不同特征进行结合来共同发挥作用，提高细粒度图像的分类效果。论文希望两个特征能分别表示图像的位置和对图形进行识别。论文提出了一种Bilinear Model。

在结构上，由于2个CNN提取的特征，进行外积相乘，从而产生了大量特征之间的两两组合。两个不同的stream代表着通过CNN得到的不同特征，然后将两个特征进行bilinear操作。

一个bilinear model由四元组构成，B=（fA,fB,P,C）,其中fA,fB为两个不同的特征提取函数，P为Pooling操作，C表示分类函数，输入图像I，位置区域l。进行如下计算。

![](https://i.imgur.com/uX8NBqB.png)

特征提取函数f（·）的作用可以看作是一个函数映射

其中池化函数的作用是将所有位置的Bilinear特征汇聚成一个特征

到此Bilinear向量即可表示该细粒度图像，后续则为经典的全连接层进行图像分类。

![](https://i.imgur.com/SyfNMqD.png)

![](https://i.imgur.com/F53OQOp.png)

这段公式的意思：两个特征fA和fB，它们的size分别是M*L和N*L，这两个特征的位置是对应的，比如都是从同一块图像区域extractor。fA和fB进行一个外积，然后把所有位置得到的外积求和，之后进行向量化，对得到的向量进行两个归一化（矩归一和L2归一）。

对同属一个子类的物体进行分类，通常需要对高度局部化、且与图像中姿态及位置无关的特征进行识别。例如，“加利福尼亚海鸥”与“环状海鸥”的区分就要求对其身体颜色纹理，或羽毛颜色的微细差异进行识别。
通常的技术分为两种：

1. 局部模型：先对局部定位，之后提取其特征，获得图像特征描述。缺陷：外观通常会随着位置、姿态及视角的改变的改变。
2. 整体模型：直接构造整幅图像的特征表示。

（基于CNN的局部模型要求对训练图像局部标注，代价昂贵，并且某些类没有明确定义的局部特征，如纹理及场景）

![](https://i.imgur.com/2fq6HRT.png)


![](https://i.imgur.com/rTykMy7.png)
